{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = mnist.load_data() #Loading handwritten digits dataset with 28x28 images (labelled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train #Splitting data into images and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAFE1JREFUeJzt3X+sVOWdx/H3B0prAyaFovYWUSihibZpAalLgt3QmHapbYKmtdE/LNsYL39At6bGlJI0GpMmxvhja7Y1ew1ETGjVRF0JISglbl3TagVDBbzVgmXhlluQxRRMf1jku3/MubsDM3Nm7syZH8/czyuZMPM858fjIXx8znOec44iAjOzVE3qdgPMzFrhEDOzpDnEzCxpDjEzS5pDzMyS5hAzs6Q5xMwsaQ4xM0uaQ8zMkvaBTu5Mkm8PMGuziFAr6y9fvjyOHz/e0LK7du16NiKWt7K/lkVE0x9gOfAGsB9Y28Dy4Y8//rT308q/6YjgiiuuiEYBO+v8m58NPA8MA/uA72TldwJ/AHZnn2vK1vk+pUx5A/ineu1tuicmaTLwY+CLwAjwiqTNEfF6s9s0s95Q4D3Vp4HbIuJVSecDuyRtz+oeiIh7yxeWdDlwA/Ap4OPAzyV9MiLer7WDVsbErgT2R8RbEfEe8BiwooXtmVmPOHPmTEOfeiJiNCJezb6fotQjm5WzygrgsYj4W0T8nlKP7Mq8fbQSYrOAw2W/R6o1TtKgpJ2SdrawLzPrkHEOKTVM0hxgIfByVrRG0muSNkianpU1lCvlWgmxaoOHFf9VETEUEYsjYnEL+zKzDhpHiM0c66Rkn8Fq25M0DXgSuDUiTgIPAfOABcAocN/YotWak9fWVq5OjlAatBtzMXCkhe2ZWY8YRy/reL0OiqQplAJsU0Q8lW3/aFn9w8CW7Oe4c6WVntgrwHxJcyV9kNJg3OYWtmdmPaKo00lJAtYDwxFxf1n5QNli1wF7s++bgRskfUjSXGA+8Ou8fTTdE4uI05LWAM8Ck4ENEbGv2e2ZWe8o8OrkUuAmYI+k3VnZOuBGSQsonSoeBFZl+90n6QngdUpXNlfnXZkEUIGNrcuTXc3aL1qc7Lpo0aJ48cUXG1p26tSpu7o93t3RGftmloZOdm5a5RAzswoOMTNLmkPMzJLVzETWbnKImVmFRm4p6hUOMTOr4J6YmSXLp5NmljyHmJklzSFmZklziJlZsiLCVyfNLG3uiZlZ0hxiZpY0h5iZJc0hZmbJ8sC+mSXPPTEzS5pDzMyS5hAzs2T5BnAzS55DzMyS5quTZpY098TMLFkeEzOz5DnEzCxpDjEzS5pDzMyS5XsnzSx5E6YnJukgcAp4HzgdEYuLaJSZddeECbHMFyLieAHbMbMeMdFCzMz6zEQKsQCekxTAv0fEUAFtMrMummgD+0sj4oikC4Htkn4bES+ULyBpEBhscT9m1kEp9cQmtbJyRBzJ/jwGPA1cWWWZoYhY7EF/s3SM3XpU71OPpNmSnpc0LGmfpO9k5TMkbZf0u+zP6Vm5JD0oab+k1yQtqrePpkNM0lRJ5499B74E7G12e2bWO4oKMeA0cFtEXAYsAVZLuhxYC+yIiPnAjuw3wJeB+dlnEHio3g5aOZ28CHha0th2fhoR21rYnpn1gCJvAI+IUWA0+35K0jAwC1gBLMsW2wj8J/C9rPzRKDXgJUkfkTSQbaeqpkMsIt4CPtvs+mbWu8YRYjMl7Sz7PVTrAp+kOcBC4GXgorFgiojRbFwdSgF3uGy1kays+BAzs/41jquTxxsZ75Y0DXgSuDUiTmZncFUXrVKWm6gtDeybWX8qcEwMSVMoBdimiHgqKz4qaSCrHwCOZeUjwOyy1S8GjuRt3yFmZmdpNMAavDopYD0wHBH3l1VtBlZm31cCz5SVfzO7SrkE+FPeeBj4dNLMqihwnthS4CZgj6TdWdk64G7gCUk3A4eA67O6rcA1wH7gz8C36u3AIWZmFQq8Ovki1ce5AK6usnwAq8ezD4eYmVVIaca+Q6xBX//612vW3XLLLbnrHjmSOy7JX//619z6TZs25db/8Y9/rFm3f//+3HXNzjXR7p00sz7knpiZJc0hZmZJc4iZWdIcYmaWLA/sm1ny3BMzs6Q5xPrQPffcU7Nuzpw5bd33qlWrcutPnTpVs27fvn1FNycZIyMjNevy/j4Bdu7cmVvf7xxiZpasIh+K2AkOMTOr4BAzs6T56qSZJc09MTNLlsfEzCx5DjEzS5pDrA/lPTPsM5/5TO66w8PDufWXXXZZbv2iRfkvQV62bFnNuiVLluSue/jw4dz62bNn59a34vTp07n1b7/9dm79wMBA0/s+dOhQbr3niTnEzCxRvnfSzJLnnpiZJc0hZmZJc4iZWdIcYmaWLA/sm1ny+qonJmkD8FXgWER8OiubATwOzAEOAt+IiHfa18zu27FjR1N1jdi2bVtL60+fPr1m3YIFC3LX3bVrV2795z73uaba1Ih679t88803c+vrzb+bMWNGzboDBw7krjvRpRRikxpY5hFg+Tlla4EdETEf2JH9NrM+MXb/ZL1PL6gbYhHxAnDinOIVwMbs+0bg2oLbZWZd0miA9UqINTsmdlFEjAJExKikCwtsk5l1Wa8EVCPaPrAvaRAYbPd+zKw4E+Hq5FFJA1kvbAA4VmvBiBgChgAkpRPvZhNUL50qNqKRgf1qNgMrs+8rgWeKaY6Z9YK+GhOT9DNgGTBT0ghwB3A38ISkm4FDwPXtbKSZdVavBFQj6oZYRNxYo+rqgttiTXrnndpT9J5//vmWtt3qHLhWfO1rX8utz5sfB7Bnz56adY8//nhTbZooigqxGvNM7wRuAcYeGLcuIrZmdd8HbgbeB/4lIp6ttw/P2DezsxR829EjwL8Bj55T/kBE3FteIOly4AbgU8DHgZ9L+mREvJ+3g2bHxMysjxU1JlZjnmktK4DHIuJvEfF7YD9wZb2VHGJmVqEDA/trJL0maYOksXGBWUD589JHsrJcDjEzqzCOEJspaWfZp5E5oQ8B84AFwChwX1auak2ptzGPiZlZhXH0so5HxOJxbvvo2HdJDwNbsp8jQPmbaS4GjtTbnntiZnaWdt87mU2QH3MdsDf7vhm4QdKHJM0F5gO/rrc998Ssay68MP+W25/85Ce59ZMm5f8/+K677qpZd+JEo2PNE1NRVydrzDNdJmkBpVPFg8AqgIjYJ+kJ4HXgNLC63pVJcIiZWRVFzROrMc90fc7yPwR+OJ59OMTMrEJfzdg3s4mll+6LbIRDzMwqOMTMLGkOMTNL2kR4KKKZ9SmPiZk1aPXq1bn1F1xwQW593iOIAN54441xt8lKHGJmljSHmJklzSFmZskq+KGIbecQM7MK7omZWdIcYmaWNIeYmSXNIWaWWbp0ac26tWvXtrTta6+9Nrd+7969ufVWnSe7mlnyfHXSzJLmnpiZJc0hZmbJ8piYmSXPIWZmSXOImVnS+urqpKQNwFeBYxHx6azsTuAW4O1ssXURsbVdjbR0XXPNNTXrpkyZkrvujh07cut/9atfNdUmy5famFgjbwB/BFhepfyBiFiQfRxgZn2knW8AL1rdnlhEvCBpTvubYma9olcCqhGN9MRqWSPpNUkbJE0vrEVm1nUp9cSaDbGHgHnAAmAUuK/WgpIGJe2UtLPJfZlZB409FLGRTy9o6upkRBwd+y7pYWBLzrJDwFC2bG9Et5nl6pVeViOa6olJGij7eR3gxwWY9ZGUTicbmWLxM2AZMFPSCHAHsEzSAiCAg8CqNrbRzDqsVwKqEY1cnbyxSvH6NrTFEvThD384t3758mqzc0ree++93HXvuOOO3Pq///3vufXWvL4KMTObWHrpVLERDjEzq9ArVx4b4RAzswop9cRamexqZn2qqKuT2WT4Y5L2lpXNkLRd0u+yP6dn5ZL0oKT92UT6RY201SFmZmdpNMAa7K09QuW912uBHRExH9iR/Qb4MjA/+wxSmlRfl0PMzCoUFWIR8QJw4pziFcDG7PtG4Nqy8kej5CXgI+fMSa3KY2LWkttvvz23fuHChTXrtm3blrvuL3/5y6baZK1r85jYRRExmu1nVNKFWfks4HDZciNZ2WjexhxiZlZhHFcnZ55zX/RQdqthM1SlrG6aOsTM7CzjnCd2PCIWj3MXRyUNZL2wAeBYVj4CzC5b7mLgSL2NeUzMzCq0+d7JzcDK7PtK4Jmy8m9mVymXAH8aO+3M456YmVUoakysxr3XdwNPSLoZOARcny2+FbgG2A/8GfhWI/twiJlZhaJCrMa91wBXV1k2gNXj3YdDzMzOMvZQxFQ4xMysQkq3HTnELNdXvvKV3Pof/OAHufUnT56sWXfXXXc11SZrP4eYmSXNIWZmSXOImVmy/FBEM0uer06aWdLcEzOzpDnEzCxZHhOzpHz0ox/NrX/wwQdz6ydPnpxbv3Xr1pp1L730Uu661j0OMTNLmgf2zSxZPp00s+Q5xMwsaQ4xM0uaQ8zMkuYQM7Nk9d1DESXNBh4FPgacofRKph9JmgE8DswBDgLfiIh32tdUa0a9eVz13v04d+7c3PoDBw7k1td73pj1ppR6Yo287eg0cFtEXAYsAVZLupzaryI3s8S1+W1HhaobYhExGhGvZt9PAcOU3spb61XkZpa4lEJsXGNikuYAC4GXqf0qcjNLWC8FVCMaDjFJ04AngVsj4qRU7Y3jVdcbBAaba56ZdUPfhZikKZQCbFNEPJUV13oV+VkiYggYyraTzpExm8BSujpZd0xMpS7XemA4Iu4vq6r1KnIzS1y/jYktBW4C9kjanZWto/aryK2HzJs3L7f+iiuuaGn73/3ud3Pr603BsN7TSwHViLohFhEvArUGwCpeRW5m6eurEDOzicchZmZJS2lg3yFmZmfpuzExM5t4HGJmljSHmJklzSFmHXXppZfWrHvuueda2vbtt9+eW79ly5aWtm+9ySFmZskq+qGIkg4Cp4D3gdMRsbjI5xE28jwxM5tg2nDb0RciYkFELM5+F/Y8QoeYmVXowL2ThT2P0CFmZhXGEWIzJe0s+1R77FYAz0naVVZ/1vMIgaafR+gxMTM7yzh7WcfLThFrWRoRR7IHp26X9NvWWng298TMrEKRp5MRcST78xjwNHAl2fMIAfKeR9gIh5iZVThz5kxDn3okTZV0/th34EvAXgp8HqFPJ/vA4GDtp39fcsklLW37F7/4RW59SvOJrHEF/r1eBDydPc7+A8BPI2KbpFco6HmEDjEzO0uRN4BHxFvAZ6uU/w8FPY/QIWZmFVLqYTvEzKyCQ8zMkuaHIppZsvxQRDNLnkPMzJLmELNCXXXVVbn13/72tzvUEpsoHGJmljSHmJklq+iHIrabQ8zMKrgnZmZJc4iZWdIcYmaWLE92NbPk9VWISZoNPAp8DDgDDEXEjyTdCdwCvJ0tui4itraroRPZ5z//+dz6adOmNb3tAwcO5Na/++67TW/b0tVvVydPA7dFxKvZExp3Sdqe1T0QEfe2r3lm1g191RPL3kQy9laSU5KGgVntbpiZdUdqY2Ljesa+pDnAQuDlrGiNpNckbZA0vcY6g2Ovc2qppWbWMR1472RhGg4xSdOAJ4FbI+Ik8BAwD1hAqad2X7X1ImIoIhY38FonM+sRKYVYQ1cnJU2hFGCbIuIpgIg4Wlb/MLClLS00s45LaWC/bk9MpdeUrAeGI+L+svKBssWuo/QaJjNLXKO9sJR6YkuBm4A9knZnZeuAGyUtoPSK8oPAqra00Frym9/8Jrf+6qvzXzhz4sSJIptjieiVgGpEI1cnXwRUpcpzwsz6VF+FmJlNPA4xM0uaQ8zMkuWHIppZ8twTM7OkOcTMLGkphZg62VhJ6RwZs0RFRLUpUQ2bNGlSnHfeeQ0t+5e//GVXt28pdE/MzCqk1BNziJlZBV+dNLOkpdQTG9fzxMys/xV9A7ik5ZLekLRf0tqi2+sQM7MKRYWYpMnAj4EvA5dTenDE5UW21SFmZhUK7IldCeyPiLci4j3gMWBFkW31mJiZVShwYH8WcLjs9wjwD0VtHDofYseB/y77PTMr60W92rZebRe4bc0qsm2XFrCNZym1qRHnnfP+jKGIGCr7XW3OWqFXDToaYhFxQflvSTu7PVGull5tW6+2C9y2ZvVa2yJieYGbGwFml/2+GDhS4PY9JmZmbfUKMF/SXEkfBG4ANhe5A4+JmVnbRMRpSWsonaJOBjZExL4i99HtEBuqv0jX9GrberVd4LY1q5fb1rKI2EobH2ff0RvAzcyK5jExM0taV0Ks3bchtELSQUl7JO0+59JxN9qyQdIxSXvLymZI2i7pd9mf03uobXdK+kN27HZLuqZLbZst6XlJw5L2SfpOVt7VY5fTrp44bqnq+OlkdhvCm8AXKV1+fQW4MSJe72hDapB0EFgcEV2fUyTpH4F3gUcj4tNZ2T3AiYi4O/sfwPSI+F6PtO1O4N2IuLfT7TmnbQPAQES8Kul8YBdwLfDPdPHY5bTrG/TAcUtVN3pibb8NoV9ExAvAuW+vXQFszL5vpPSPoONqtK0nRMRoRLyafT8FDFOaOd7VY5fTLmtBN0Ks2m0IvfQXGcBzknZJGux2Y6q4KCJGofSPAriwy+051xpJr2Wnm1051S0naQ6wEHiZHjp257QLeuy4paQbIdb22xBatDQiFlG66351dtpkjXkImAcsAEaB+7rZGEnTgCeBWyPiZDfbUq5Ku3rquKWmGyHW9tsQWhERR7I/jwFPUzr97SVHs7GVsTGWY11uz/+JiKMR8X5EnAEepovHTtIUSkGxKSKeyoq7fuyqtauXjluKuhFibb8NoVmSpmYDrkiaCnwJ2Ju/VsdtBlZm31cCz3SxLWcZC4jMdXTp2EkSsB4Yjoj7y6q6euxqtatXjluqujLZNbuE/K/8/20IP+x4I6qQ9AlKvS8o3c3w0262TdLPgGWUnihwFLgD+A/gCeAS4BBwfUR0fIC9RtuWUTolCuAgsGpsDKrDbbsK+C9gDzD2TJl1lMafunbsctp1Iz1w3FLlGftmljTP2DezpDnEzCxpDjEzS5pDzMyS5hAzs6Q5xMwsaQ4xM0uaQ8zMkva/kXtoGgNhuAAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #Displaying the image using plotting library\n",
    "plt.imshow(X_test[0],cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data to bring in range 0 to 1 from 0 to 255\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(-1,X_test.shape[1]*X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #Flattened the images from 28x28 to 784 to feed to neural network neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #Making a feed-forward artificial neural network with sequential layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding layers and activations\n",
    "model.add(Dense(128,activation='relu',input_shape=(784,)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#Categorical crossentropy is used to define error for multiple classes (0 to 9 in this case)\n",
    "#Adam optimizer uses a combination of RMSProp and Gradient Descent Optimization technique\n",
    "#We are judging the model on its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 26s 534us/step - loss: 2.0936 - acc: 0.2528 - val_loss: 1.7294 - val_acc: 0.3306\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 1.3607 - acc: 0.4923 - val_loss: 1.0187 - val_acc: 0.5997\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.7748 - acc: 0.7138 - val_loss: 0.5230 - val_acc: 0.8493\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.4020 - acc: 0.8834 - val_loss: 0.3103 - val_acc: 0.9221\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2480 - acc: 0.9380 - val_loss: 0.2365 - val_acc: 0.9379\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1834 - acc: 0.9548 - val_loss: 0.2034 - val_acc: 0.9476\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1487 - acc: 0.9626 - val_loss: 0.1890 - val_acc: 0.9512\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1256 - acc: 0.9687 - val_loss: 0.1770 - val_acc: 0.9544\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1048 - acc: 0.9730 - val_loss: 0.1901 - val_acc: 0.9537\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0888 - acc: 0.9767 - val_loss: 0.1700 - val_acc: 0.9589\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0753 - acc: 0.9814 - val_loss: 0.1628 - val_acc: 0.9612\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0650 - acc: 0.9841 - val_loss: 0.1720 - val_acc: 0.9609\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0611 - acc: 0.9846 - val_loss: 0.1787 - val_acc: 0.9580\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0527 - acc: 0.9868 - val_loss: 0.1643 - val_acc: 0.9633\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0416 - acc: 0.9909 - val_loss: 0.1666 - val_acc: 0.9621\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0359 - acc: 0.9921 - val_loss: 0.1668 - val_acc: 0.9626\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0298 - acc: 0.9941 - val_loss: 0.1760 - val_acc: 0.9632\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0276 - acc: 0.9944 - val_loss: 0.1750 - val_acc: 0.9632\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0260 - acc: 0.9947 - val_loss: 0.1817 - val_acc: 0.9618\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0231 - acc: 0.9952 - val_loss: 0.1900 - val_acc: 0.9631\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0203 - acc: 0.9959 - val_loss: 0.1885 - val_acc: 0.9627\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0222 - acc: 0.9952 - val_loss: 0.1956 - val_acc: 0.9618\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0236 - acc: 0.9940 - val_loss: 0.1987 - val_acc: 0.9608\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0165 - acc: 0.9964 - val_loss: 0.1866 - val_acc: 0.9652\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0135 - acc: 0.9976 - val_loss: 0.1929 - val_acc: 0.9641\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0121 - acc: 0.9982 - val_loss: 0.1972 - val_acc: 0.9618\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0126 - acc: 0.9977 - val_loss: 0.1972 - val_acc: 0.9650\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0120 - acc: 0.9980 - val_loss: 0.2081 - val_acc: 0.9622\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0110 - acc: 0.9980 - val_loss: 0.2043 - val_acc: 0.9645\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0108 - acc: 0.9978 - val_loss: 0.2074 - val_acc: 0.9645\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0123 - acc: 0.9971 - val_loss: 0.2165 - val_acc: 0.9635\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0189 - acc: 0.9950 - val_loss: 0.2317 - val_acc: 0.9599\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0256 - acc: 0.9932 - val_loss: 0.2256 - val_acc: 0.9628\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9963 - val_loss: 0.2021 - val_acc: 0.9656\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0132 - acc: 0.9967 - val_loss: 0.2308 - val_acc: 0.9612\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0128 - acc: 0.9967 - val_loss: 0.2099 - val_acc: 0.9655\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0103 - acc: 0.9979 - val_loss: 0.2080 - val_acc: 0.9657\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0095 - acc: 0.9980 - val_loss: 0.2171 - val_acc: 0.9644\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.2182 - val_acc: 0.9636\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0077 - acc: 0.9986 - val_loss: 0.2368 - val_acc: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c54bd6630>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model using the training data\n",
    "model.fit(X_train,Y_train,batch_size=1000,epochs=40,validation_split=0.2)\n",
    "#All the above parameters in fit function are hyperparameters, change them and experiment with them to see what different results can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating test accuracy\n",
    "import numpy as np\n",
    "total = len(X_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "corr=0\n",
    "for i in range(len(X_test)):\n",
    "    if np.argmax(Y_pred[i]) == np.argmax(Y_test[i]):\n",
    "        corr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = corr/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#working of argmax\n",
    "np.argmax(Y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
